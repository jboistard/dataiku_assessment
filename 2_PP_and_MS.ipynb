{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataiku Data Scientist Technical Assessment**\n",
    "### Author : Jules Boistard\n",
    "### Submission date : January 18th, 2022\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **#2 : Pre-processing and preliminary model selection**\n",
    "\n",
    "The goal here is to iteratively find the best pre-processing pipeline based on a simple basic machine learning model, adding/removing steps along the way.\n",
    "\n",
    "This section **does not** aim at finding the best performing model. This will be the focus of the next section (\"model selection\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.1 : Importing and splitting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test files\n",
    "# NB : we do not want instance weight for machine learning training\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data/train_clean.csv\", header=0)\n",
    "test = pd.read_csv(\"data/test_clean.csv\", header=0)\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# Split datasets into features set and target variable\n",
    "# Note : target classes \"-50k\" and \">50k\" will respectively be labelled 0 and 1\n",
    "X_train = train.iloc[:, :-2]\n",
    "X_test = test.iloc[:, :-2]\n",
    "y_train = train.iloc[:, -2].map(lambda s: 0 if \"-\" in s else 1)\n",
    "y_test = test.iloc[:, -2].map(lambda s: 0 if \"-\" in s else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.2 : Building baseline models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a very first step, we will compare two very basic models, on which we will perform minimal pre-processing :\n",
    "- One linear : a logistic regression model\n",
    "- One non linear : a decision tree\n",
    "\n",
    "Our first pre-processing pipeline will consist in 4 basic steps :\n",
    "1. Drop columns with ~50% NaN Values (see part 1 : EDA)\n",
    "2. Impute NaN values with most frequent class for other columns wit missing values (see part 1 : EDA)\n",
    "3. Encode our remaining categorical features with ordinal encoding for the decision tree (for minimal computation time) and one hot encoding for the logistic regression model\n",
    "4. Perform standard scaling for our numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first define different sets of features\n",
    "base_num_cols = [\"age\", \"wage per hour\", \"capital gains\", \"capital losses\", \"dividends from stocks\", \"num persons worked for employer\", \"weeks worked in year\"]\n",
    "base_cat_cols = [col for col in X_train.columns if col not in base_num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline builder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "def build_preprocessor(ordinal_encoding=True, cols_to_drop=[]):    \n",
    "\n",
    "    cat_cols = list(set(base_cat_cols).difference(set(cols_to_drop)))\n",
    "    num_cols = list(set(base_num_cols).difference(set(cols_to_drop)))\n",
    "\n",
    "    categories = [sorted(data[col].dropna().unique()) for col in cat_cols]\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OrdinalEncoder(categories=categories) if ordinal_encoding else OneHotEncoder(categories=categories))\n",
    "    ])\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"dropper\", \"drop\", cols_to_drop),\n",
    "        (\"categorical\", cat_transformer, cat_cols),\n",
    "        (\"numerical\", num_transformer, num_cols)\n",
    "    ], remainder=\"passthrough\")\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation procedure\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, curves=True):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Low income (<50k)\", \"High income (>50k)\"], digits=4))\n",
    "\n",
    "    if curves:\n",
    "        N, train_score, val_score = learning_curve(model, X_train, y_train, scoring=\"f1_macro\")\n",
    "        plt.figure()\n",
    "        plt.plot(N, train_score.mean(axis=1), label=\"train score\")\n",
    "        plt.plot(N, val_score.mean(axis=1), label=\"val score\")\n",
    "        plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important** : we do not value one of the 2 target classes more than the other. In other words, good predictions are equally important for the \"low income\" and \"high income\" classes. On the other hand, accuracy will not do because of class imbalance (~94%/6%). We can therefore choose the **macro averaged f1-score** as our performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9871    0.8435    0.9097     72669\n",
      "High income (>50k)     0.3201    0.8696    0.4680      6157\n",
      "\n",
      "          accuracy                         0.8456     78826\n",
      "         macro avg     0.6536    0.8566    0.6888     78826\n",
      "      weighted avg     0.9350    0.8456    0.8752     78826\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building and evaluating a baseline logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = Pipeline(steps=[\n",
    "    (\"preprocessing\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop = [\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42))    \n",
    "])\n",
    "\n",
    "evaluate_model(lr_clf, X_train, y_train, X_test, y_test, curves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9552    0.9536    0.9544     72669\n",
      "High income (>50k)     0.4626    0.4718    0.4672      6157\n",
      "\n",
      "          accuracy                         0.9159     78826\n",
      "         macro avg     0.7089    0.7127    0.7108     78826\n",
      "      weighted avg     0.9167    0.9159    0.9163     78826\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building and evaluating a baseline decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(dt_clf, X_train, y_train, X_test, y_test, curves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple things worth noting :\n",
    "- The **decision tree performs a little bit better** than the logistic regression model. The difference is however not that big. We will therefore continue to compare the both of them throughout the next steps.\n",
    "- Depending on the context, we could favor one based on individual f1, recall or sensitivity scores for one of the two classes.\n",
    "- Overall, the performance is not very good. While the f1 score is not too bad on the majority class (low income) it is, as could be expected, quite poor for the minority class (high income).\n",
    "\n",
    "To adress the issue of underfitting, we will try the following pre-processing operations :\n",
    "- Perform over-sampling to increase the representation of the minority class\n",
    "- Perform some feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.3 : Over sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try and perform over sampling through a SMOTE algorithm (Synthetic Minority Oversampling TEchnique). The goal is to artificially create observations for the minority class \"in between\" real observations from the same class in the feature space, up until the two classes have an equal number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9855    0.8517    0.9137     72669\n",
      "High income (>50k)     0.3273    0.8520    0.4730      6157\n",
      "\n",
      "          accuracy                         0.8517     78826\n",
      "         macro avg     0.6564    0.8518    0.6933     78826\n",
      "      weighted avg     0.9341    0.8517    0.8793     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try and perform over sampling on the log reg model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "\n",
    "lr_clf_with_smote = imPipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"resampling\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"classifier\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(lr_clf_with_smote, X_train, y_train, X_test, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9576    0.9407    0.9491     72669\n",
      "High income (>50k)     0.4206    0.5082    0.4603      6157\n",
      "\n",
      "          accuracy                         0.9069     78826\n",
      "         macro avg     0.6891    0.7244    0.7047     78826\n",
      "      weighted avg     0.9156    0.9069    0.9109     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same with decision tree\n",
    "dt_clf_with_smote = imPipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"resampling\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"classifier\", DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "evaluate_model(dt_clf_with_smote, X_train, y_train, X_test, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe two different results :\n",
    "- Oversampling did improve the average f1 score of our logistic regression model, although not very much (~ +0.5%)\n",
    "- The same operation dit **not** improve the performance of our decision tree (~ -1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.4 : Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried adding observations. Let us now try to add features.\n",
    "\n",
    "Since we want to preserve some degree of \"explainability\" in our model, we will not make us of feature engineering algorithm such as polynomial features.\n",
    "\n",
    "However, we can try and add a couple of features **manually**, following from what we saw during our EDA (see part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_binary_features(X):\n",
    "\n",
    "    X_ = X.copy()\n",
    "\n",
    "    X_[\"adult\"] = X_[\"age\"].map(lambda val: 1 if val >= 18 else 0)\n",
    "\n",
    "    X_[\"working\"] = X_[\"weeks worked in year\"].map(lambda val: 1 if val > 0 else 0)\n",
    "\n",
    "    X_[\"extra earnings\"] = X_.apply(lambda row: 1 if row[[\"capital gains\", \"dividends from stocks\"]].sum() > 0 else 0, axis=1)\n",
    "\n",
    "    X_[\"is hispanic\"] = X_[\"hispanic origin\"].map(lambda val: 0 if val == \"All other\" else 1)\n",
    "\n",
    "    X_[\"high academic level\"] = X_[\"education\"].map(\n",
    "        lambda val: 1 if val in [\"Bachelors degree(BA AB BS)\", \"Masters degree(MA MS MEng MEd MSW MBA)\", \"Prof school degree (MD DDS DVM LLB JD)\", \"Doctorate degree(PhD EdD)\"] else 0\n",
    "    )\n",
    "    \n",
    "    # According to occupation recodes from documentation page 146\n",
    "    X_[\"executive or manager\"] = X_[\"detailed occupation recode\"].map(lambda val: 1 if val <=3 else 0) \n",
    "\n",
    "    # According to industry recodes from documentation page 131\n",
    "    X_[\"work in agriculture or industry\"] = X_[\"detailed industry recode\"].map(lambda val: 1 if val<=20 else 0)\n",
    "    X_[\"work in finance, insurance, real estate or business management\"] = X_[\"detailed industry recode\"].map(lambda val: 1 if val in [32, 33, 34, 37] else 0)\n",
    "\n",
    "    return X_\n",
    "\n",
    "X_train_extra_features = add_binary_features(X_train)\n",
    "X_test_extra_features = add_binary_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9873    0.8469    0.9117     72669\n",
      "High income (>50k)     0.3252    0.8710    0.4736      6157\n",
      "\n",
      "          accuracy                         0.8487     78826\n",
      "         macro avg     0.6562    0.8589    0.6926     78826\n",
      "      weighted avg     0.9355    0.8487    0.8775     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try our new features with the log reg model\n",
    "lr_clf_with_extra_features = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(lr_clf_with_extra_features, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9562    0.9559    0.9560     72669\n",
      "High income (>50k)     0.4813    0.4835    0.4824      6157\n",
      "\n",
      "          accuracy                         0.9190     78826\n",
      "         macro avg     0.7188    0.7197    0.7192     78826\n",
      "      weighted avg     0.9191    0.9190    0.9190     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same with decision tree\n",
    "dt_clf_with_extra_features = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(dt_clf_with_extra_features, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we do have a slight improvement for both models compared to the baseline ones (~ + 0.4% for log reg and +0.6% for decision tree)\n",
    "\n",
    "We can now try to find which of the features had the most \"impact\" on prediction in the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>executive or manager</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>region of previous residence</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fill inc questionnaire for veteran's admin</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>age</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>detailed household and family stat</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>state of previous residence</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weeks worked in year</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family members under 18</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>detailed occupation recode</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>capital losses</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>working</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>country of birth father</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>work in agriculture or industry</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>class of worker</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>education</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hispanic origin</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>major occupation code</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>detailed household summary in household</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>country of birth mother</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reason for unemployment</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high academic level</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>capital gains</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num persons worked for employer</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>year</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dividends from stocks</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>major industry code</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>marital stat</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wage per hour</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>veterans benefits</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>enroll in edu inst last wk</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>race</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tax filer stat</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>is hispanic</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detailed industry recode</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>country of birth self</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>adult</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>live in this house 1 year ago</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>work in finance, insurance, real estate or bus...</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>member of a labor union</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>own business or self employed</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extra earnings</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>full or part time employment stat</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  coef\n",
       "40                               executive or manager 0.172\n",
       "29                       region of previous residence 0.129\n",
       "33         fill inc questionnaire for veteran's admin 0.127\n",
       "15                                                age 0.058\n",
       "38                 detailed household and family stat 0.050\n",
       "14                        state of previous residence 0.049\n",
       "30                               weeks worked in year 0.041\n",
       "1                             family members under 18 0.038\n",
       "24                         detailed occupation recode 0.032\n",
       "12                                     capital losses 0.028\n",
       "32                                            working 0.028\n",
       "34                            country of birth father 0.026\n",
       "19                    work in agriculture or industry 0.019\n",
       "28                                    class of worker 0.016\n",
       "35                                          education 0.016\n",
       "6                                     hispanic origin 0.015\n",
       "8                               major occupation code 0.013\n",
       "25            detailed household summary in household 0.012\n",
       "27                            country of birth mother 0.012\n",
       "3                             reason for unemployment 0.011\n",
       "31                                        citizenship 0.010\n",
       "7                                 high academic level 0.010\n",
       "11                                      capital gains 0.009\n",
       "18                    num persons worked for employer 0.009\n",
       "23                                                sex 0.009\n",
       "26                                               year 0.009\n",
       "16                              dividends from stocks 0.007\n",
       "21                                major industry code 0.007\n",
       "10                                       marital stat 0.005\n",
       "17                                      wage per hour 0.005\n",
       "13                                  veterans benefits 0.005\n",
       "5                          enroll in edu inst last wk 0.004\n",
       "20                                               race 0.004\n",
       "43                                     tax filer stat 0.004\n",
       "39                                        is hispanic 0.003\n",
       "2                            detailed industry recode 0.002\n",
       "22                              country of birth self 0.002\n",
       "42                                              adult 0.001\n",
       "9                       live in this house 1 year ago 0.001\n",
       "41  work in finance, insurance, real estate or bus... 0.001\n",
       "37                            member of a labor union 0.000\n",
       "4                       own business or self employed 0.000\n",
       "0                                      extra earnings 0.000\n",
       "36                  full or part time employment stat 0.000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance in the decision tree\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "dt_feature_imp = pd.DataFrame(data={\n",
    "    \"features\": list(set(X_train_extra_features.columns).difference(set([\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]))),\n",
    "    \"coef\": list(dt_clf_with_extra_features[\"classifier\"].feature_importances_)\n",
    "})\n",
    "\n",
    "dt_feature_imp.sort_values(\"coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, one of our custom features (executive or manager) is ranking first. On the other hand, the other added features did not provide as much.\n",
    "\n",
    "Note that if we have to deal with overfitting with a tree-based model, we could try to perform feature selection based on this ranking (eliminating, for instance, the N lowest ranking features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.5 : More complex models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we found a couple of preprocessing tricks to improve model performance, there is still room for improvement. Before diving into fine-tuning, we can try out a couple of different models, a little bit more elaborate than our two baselines models.\n",
    "\n",
    "Following the results above, we will use our newly created features. The will get rid of SMOTE resampling for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9514    0.9872    0.9690     72669\n",
      "High income (>50k)     0.7283    0.4052    0.5207      6157\n",
      "\n",
      "          accuracy                         0.9417     78826\n",
      "         macro avg     0.8398    0.6962    0.7448     78826\n",
      "      weighted avg     0.9340    0.9417    0.9340     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(rf_clf, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9528    0.9876    0.9699     72669\n",
      "High income (>50k)     0.7426    0.4221    0.5383      6157\n",
      "\n",
      "          accuracy                         0.9434     78826\n",
      "         macro avg     0.8477    0.7049    0.7541     78826\n",
      "      weighted avg     0.9363    0.9434    0.9362     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosted trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbt_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(gbt_clf, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9824    0.8895    0.9336     72669\n",
      "High income (>50k)     0.3836    0.8116    0.5209      6157\n",
      "\n",
      "          accuracy                         0.8834     78826\n",
      "         macro avg     0.6830    0.8505    0.7273     78826\n",
      "      weighted avg     0.9356    0.8834    0.9014     78826\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", SGDClassifier(loss=\"log\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(sgd_clf, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any fine-tuning, we can already see that all of these models already outperform our two baselines models.\n",
    "\n",
    "In the next section, we will compare them with different sets of hyperparameters to find the best predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data for futur use and save computation time\n",
    "\n",
    "tree_preprocessor = build_preprocessor(\n",
    "    ordinal_encoding=True,\n",
    "    cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    ")\n",
    "X_train_trees = tree_preprocessor.fit_transform(X_train_extra_features)\n",
    "X_test_trees = tree_preprocessor.fit_transform(X_test_extra_features)\n",
    "\n",
    "sgd_preprocessor = build_preprocessor(\n",
    "    ordinal_encoding=False, #One hot encoding\n",
    "    cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    ")\n",
    "X_train_sgd = sgd_preprocessor.fit_transform(X_train_extra_features)\n",
    "X_test_sgd = sgd_preprocessor.fit_transform(X_test_extra_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.6 : A note on feature selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into fine tuning, it is worth noting that feature selection can sometimes improve model performance, getting rid of noise and avoiding dimensionality issues.\n",
    "\n",
    "Since we do not have a major problem of overfitting, we will not perform feature selection here.\n",
    "\n",
    "There is an example of feature selection for the SGD classifier below, yielding a lower f1 score than the \"raw\" equivalent classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9837    0.8697    0.9232     72669\n",
      "High income (>50k)     0.3504    0.8296    0.4927      6157\n",
      "\n",
      "          accuracy                         0.8666     78826\n",
      "         macro avg     0.6670    0.8497    0.7079     78826\n",
      "      weighted avg     0.9342    0.8666    0.8896     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sgd_clf_with_fs = Pipeline(steps=[\n",
    "    (\"feature_selec\", SelectFromModel(\n",
    "        estimator=LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42),\n",
    "        threshold=\"median\"\n",
    "    )),\n",
    "    (\"classifier\", SGDClassifier(loss=\"log\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(sgd_clf_with_fs, X_train_sgd, y_train, X_test_sgd, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### **#3 : Fine tuning and model assessment**\n",
    "\n",
    "In this final section, we will perform grid search combined with cross validation to find the best set of hyper parameters for each of our three models, which are :\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Stochastic Gradient Descent\n",
    "\n",
    "We will then pick the overall best performing model for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#3.1 : Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 500, 1000],\n",
    "    \"criterion\" : [\"entropy\"],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "}\n",
    "\n",
    "rf_gscsv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_params,\n",
    "    scoring=\"f1_macro\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_gscsv = rf_gscsv.fit(X_train_trees, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7491440475165694\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'n_estimators': 1000}\n",
      "0.7550356625978092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(rf_gscsv.best_score_)\n",
    "print(rf_gscsv.best_params_)\n",
    "y_pred = rf_gscsv.best_estimator_.predict(X_test_trees)\n",
    "score = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#3.2 : Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10052/289186813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgb_gscsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgb_gscsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_trees\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dataiku_assessment\\venv\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gb_params = {\n",
    "    \"n_estimators\": [50, 100, 500],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.001],\n",
    "    \"max_depth\": [3, 5, 10],\n",
    "}\n",
    "\n",
    "gb_gscsv = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(),\n",
    "    param_grid=gb_params,\n",
    "    scoring=\"f1_macro\",\n",
    "    verbose=1,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "gb_gscsv = gb_gscsv.fit(X_train_trees, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#3.3 : SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_params = {\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"loss\": [\"log\"],\n",
    "    \"class_weight\": [\"balanced\"]\n",
    "}\n",
    "\n",
    "sgd_gscsv = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(),\n",
    "    param_grid=sgd_params,\n",
    "    scoring=\"f1_macro\",\n",
    "    verbose=1,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "sgd_gscsv = sgd_gscsv.fit(X_train_sgd, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b0d1bc37e4150564005d2f0757eca3230f3c8295ef7a49a1da484b71996b598"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
