{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataiku Data Scientist Technical Assessment**\n",
    "### Author : Jules Boistard\n",
    "### Submission date : January 18th, 2022\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **#2 : Pre-processing and preliminary model selection**\n",
    "\n",
    "The goal here is to iteratively find the best pre-processing pipeline based on a simple basic machine learning model, adding/removing steps along the way.\n",
    "\n",
    "This section **does not** aim at finding the best performing model. This will be the focus of the next section (\"model selection\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.1 : Importing and splitting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test files\n",
    "# NB : we do not want instance weight for machine learning training\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data/train_clean.csv\", header=0)\n",
    "test = pd.read_csv(\"data/test_clean.csv\", header=0)\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# Split datasets into features set and target variable\n",
    "# Note : target classes \"-50k\" and \">50k\" will respectively be labelled 0 and 1\n",
    "X_train = train.iloc[:, :-2]\n",
    "X_test = test.iloc[:, :-2]\n",
    "y_train = train.iloc[:, -2].map(lambda s: 0 if \"-\" in s else 1)\n",
    "y_test = test.iloc[:, -2].map(lambda s: 0 if \"-\" in s else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.2 : Building baseline models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a very first step, we will compare two very basic models, on which we will perform minimal pre-processing :\n",
    "- One linear : a logistic regression model\n",
    "- One non linear : a decision tree\n",
    "\n",
    "Our first pre-processing pipeline will consist in 4 basic steps :\n",
    "1. Drop columns with ~50% NaN Values (see part 1 : EDA)\n",
    "2. Impute NaN values with most frequent class for other columns wit missing values (see part 1 : EDA)\n",
    "3. Encode our remaining categorical features with ordinal encoding for the decision tree (for minimal computation time) and one hot encoding for the logistic regression model\n",
    "4. Perform standard scaling for our numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first define different sets of features\n",
    "base_num_cols = [\"age\", \"wage per hour\", \"capital gains\", \"capital losses\", \"dividends from stocks\", \"num persons worked for employer\", \"weeks worked in year\"]\n",
    "base_cat_cols = [col for col in X_train.columns if col not in base_num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline builder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "def build_preprocessor(ordinal_encoding=True, cols_to_drop=None, cols_to_keep=None):\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        cat_cols = list(set(base_cat_cols).difference(set(cols_to_drop)))\n",
    "        num_cols = list(set(base_num_cols).difference(set(cols_to_drop)))\n",
    "    elif cols_to_keep:\n",
    "        cat_cols = list(set(base_cat_cols).intersection(set(cols_to_keep)))\n",
    "        num_cols = list(set(base_num_cols).intersection(set(cols_to_keep)))\n",
    "    else:\n",
    "        cat_cols = base_cat_cols\n",
    "        num_cols = base_num_cols\n",
    "\n",
    "    categories = [sorted(data[col].dropna().unique()) for col in cat_cols]\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OrdinalEncoder(categories=categories) if ordinal_encoding else OneHotEncoder(categories=categories))\n",
    "    ])\n",
    "\n",
    "    num_transformer = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"dropper\", \"drop\", cols_to_drop),\n",
    "        (\"categorical\", cat_transformer, cat_cols),\n",
    "        (\"numerical\", num_transformer, num_cols)\n",
    "    ], remainder=\"passthrough\")\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation procedure\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, curves=True):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Low income (<50k)\", \"High income (>50k)\"], digits=4))\n",
    "\n",
    "    if curves:\n",
    "        N, train_score, val_score = learning_curve(model, X_train, y_train, scoring=\"f1_macro\")\n",
    "        plt.figure()\n",
    "        plt.plot(N, train_score.mean(axis=1), label=\"train score\")\n",
    "        plt.plot(N, val_score.mean(axis=1), label=\"val score\")\n",
    "        plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important** : we do not value one of the 2 target classes more than the other. In other words, good predictions are equally important for the \"low income\" and \"high income\" classes. On the other hand, accuracy will not do because of class imbalance (~94%/6%). We can therefore choose the **macro averaged f1-score** as our performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9871    0.8435    0.9097     72669\n",
      "High income (>50k)     0.3201    0.8696    0.4680      6157\n",
      "\n",
      "          accuracy                         0.8456     78826\n",
      "         macro avg     0.6536    0.8566    0.6888     78826\n",
      "      weighted avg     0.9350    0.8456    0.8752     78826\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwFklEQVR4nO3deXwV9bn48c+TPRAgIYQ1LBECCrIHZHFBK4gr2ltZ1AqtQnHhShcUe6+31trfrbVXqxZRtIK1sgkqqCiCFbUISAibIEvYwxpCEiAkZHt+f8wETkICJ5Dk5OQ879frvDLnO8t5JpPMM99l5oiqYowxJvAE+ToAY4wxvmEJwBhjApQlAGOMCVCWAIwxJkBZAjDGmAAV4usAKqNJkybarl07X4dhjDF+Zc2aNUdVNa5suV8lgHbt2pGcnOzrMIwxxq+IyJ7yyq0JyBhjApQlAGOMCVCWAIwxJkBZAjDGmABlCcAYYwKUJQBjjAlQXiUAERkqIltFJFVEJpcz/0URWee+tolIlse80SKy3X2N9ijvLSIb3W2+LCJSJXtkjDHGKxe8D0BEgoEpwGAgDVgtIgtVdXPJMqr6S4/lJwA93enGwO+AJECBNe66mcBUYCywClgEDAU+raL9KuX9lDTST5ymRXQkraIjaBkdSdMGEQQHWc4xxgQub24E6wukqupOABGZDQwDNlew/Cickz7ATcASVT3mrrsEGCoiy4CGqrrSLf8HcCfVlAA+3nCQf205UqosOEho3jCClm5CaNHobHJoGR1Jy0aRNIwMwSomxpi6ypsE0ArY5/E+DbiqvAVFpC2QAPzrPOu2cl9p5ZSXt81xwDiANm3aeBHuud4a04cTeQUczM7jQFYuB7JKfuZyIDuXtXuzWJR9kIKi0l+OUz8s+GxCiI6gZSNnukV0BK2iI2neKILwkOCLiskYY3ytqh8FMRKYp6pFVbVBVZ0GTANISkq66K8vaxARSoOIUDo2a1Du/OJi5ejJ0xzI9kgOJYkiO5dNB7I5ejL/nPXiGoTTspFHzSE6stT72PphBFlTkzGmFvImAewHWnu8j3fLyjMSeKTMuoPKrLvMLY/3cps1IihIaNowgqYNI+jROrrcZfIKijjkJoj9WblnahT7s3LZdvgEy7amk1tQOveFBQfRwqP20LJUM5MzXT/crx7JZIypI7w586wGEkUkAeckPRK4p+xCInI5EAOs8CheDPw/EYlx3w8BnlTVYyJyXET64XQC3w+8cvG7UTMiQoNp16Q+7ZrUL3e+qpKdW+Akh6w8DmQ7yeFAVh4Hs3JZseMoh47nUVymHtMoMvScmoNnomjWIJyQYBuxa4ypWhdMAKpaKCKP4pzMg4G3VHWTiDwDJKvqQnfRkcBs9fiWefdE/wecJALwTEmHMPAwMAOIxOn8rZYO4JokIkTXCyO6XhhdWjYqd5nComKOnDh9puZwICuPg9m57vs8kvdkkp1bUGqdIIFmDSPK7Y9o6fZHNIoMtQ5rY0yliMf5utZLSkrSQHgcdM7pQg5mOwnhQFYuB7M8prOdpJFfVFxqncjQ4LO1hjLJoUV0JC0aRRARah3WxgQiEVmjqklly63xuRaqHx5Ch6YN6NC04g7rjJz8MwnBMznsz8pjy6EjpJ84fc56TaLC3CGvTqJo5Q5/LUkUTaLCrcPamABiCcAPBQUJcQ3CiWsQTvcKOqxPFxZxOPu028xUMuTVSRQ703P49/aj5OSX7rAODRaaN3KalxKa1KdH62h6tY2hQ1yUJQZj6iBLAHVUeEgwbWLr0Sa2XrnzVZXjeYXnJIeS16ffH2L2aucWjgYRIU4yaBNDr7Yx9GgdTaPI0JrcHWNMNbAEEKBEhEaRoTSKDOWKFg3Pma+q7DyaQ8qeTNbuyyJlTyav/Gv7mRFMHZpG0avN2aRgtQRj/I91AhuvnTxdyHo3GaTsdRJD1ilnxFJJLaFnmxh6tYmmZ+sYGtWzWoIxtYF1AptLFhUewsAOTRjYoQng1BJ2Hc0hZW8WKXszSdmTyd8qqCX0bBNDYlOrJRhTm1gNwFSpk6cL2bDPTQh7s1i7N5PMklpCeAg92lgtwZiaZjUAUyOiwkMY0KEJA8qpJax1k4JnLaF9XP0z/Qi9rJZgTI2yGoCpcd7WEnq2iaaX1RKMuWRWAzC1Rnm1hN0Zp850Ll+oltChaZR9mY8xVcBqAKZWOnm6kA1pWazde3bUkWctoXvraKcfoW2M1RKMuQCrARi/EhUewoD2TRjQvnQtwelHyCRlTxZ/+zK1VC3B6VyOoVfbaBKbNrBagjEXYDUA47dyThey3q0llHQwH8txvrQnKrzk7uWz/QnR9cJ8HLExvmE1AFPn1C+nlrAn45Tbj3BuLeGykr4EqyUYA1gNwNRxOacL2ZCW7dy5XE4toXvrRmeSgtUSTF1lNQATkOqHh9C/fSz928cCTi1h77FTZ2oIKXszeXXZDorcasJlTdy+hLbOHcwdm1ktwdRdVgMwAe9UfiHr92Wzdp+TFNbuzSSjnFpCT/fu5Zj6Vksw/sVqAMZUoF6Y1RJMYLIagDFeOJV/ti+hbC2hflgwHco8wsIzHZT9rubS8zzLyyQRKXeSsl/97Lleqe2dZ9sVfX2097FWvN75Yi2ZG1MvlAevuYxOzcv/1jtTtSqqAVgCMOYiqCr7juWeGXG062hOBcuVeY+WO8/r5UovVPl13NjLm3duDOXPPP863u3f3mOnyMkv5Mc94/nl4ETiY8r/4iJTNSwBGGNqjcycfF5dlsrbK/aAwn392vLoDR1obP0r1cISgDGm1tmflctfl2xjfkoa9cJCGHftZTxwdQL1w617sipVlACCvFx5qIhsFZFUEZlcwTLDRWSziGwSkZke5c+JyPfua4RH+QwR2SUi69xXj4vYL2OMH2sVHcnzd3fns4nX0r99LC8s2cZ1zy/jHyt2k19Y7Ovw6rwL1gBEJBjYBgwG0oDVwChV3eyxTCIwF7hBVTNFpKmqHhGRW4GJwM1AOLAM+JGqHheRGcDHqjrP22CtBmBM3bZmzzGe+3Qr3+0+RpvG9fj1kI7c3q2lfUfEJbqUGkBfIFVVd6pqPjAbGFZmmbHAFFXNBFDVI255Z+BrVS1U1RxgAzD0YnfCGFO39W7bmDm/6Mf0MX2oFxbMY7PXcfvf/s1X29Lxp+Zqf+FNAmgF7PN4n+aWeeoIdBSR5SKyUkRKTvLrgaEiUk9EmgDXA6091vujiGwQkRdFJLy8DxeRcSKSLCLJ6enpXu2UMcZ/iQjXX96URf95DS+O6E52bgGj3/qOUW+sZO3eTF+HV6d41QfghRAgERgEjALeEJFoVf0cWAR8C8wCVgBF7jpPApcDfYDGwBPlbVhVp6lqkqomxcXFVVG4xpjaLihIuKtnPF/8+jqevr0z2w+f5K5Xv2X8O2tIPXLS1+HVCd4kgP2UvmqPd8s8pQELVbVAVXfh9BkkAqjqH1W1h6oOxrkLZJtbflAdp4HpOE1NxhhTSnhIMGMGJvDV49cz8cZEvtmezpAXv2Ly/A0czM71dXh+zZsEsBpIFJEEEQkDRgILyyzzIc7VP25TT0dgp4gEi0isW94N6AZ87r5v4f4U4E7g+0vcF2NMHRYVHsLEGzvy1ePXc3//dsxPSWPQ88v430U/kHUq39fh+aULDrZV1UIReRRYDAQDb6nqJhF5BkhW1YXuvCEishmniWeSqmaISATwjXub+HHgPlUtdDf9rojE4dQK1gHjq3jfjDF1UJOocJ6+owsPXJ3Ai0u2Me2bncz6bi/jB7XnZwMSiAwL9nWIfsNuBDPG+LUfDh7n+cVb+deWIzRrGM5jP+rI3UnxhAZXVRen/7ukG8GMMaa2uqJFQ94a04e5v+hPq+hIfvvBRm568Ws+2XDQho5egCUAY0yd0DehMfMfGsAb9ycRHCQ8MjOFYVOWszz1qK9Dq7UsARhj6gwRYXDnZnw28Vqe/0k3jp44zb1vruKnf1/FxrRsX4dX61gfgDGmzsorKOKfK/fwty9TyTpVwK3dWvCbIZ1IaFLf16HVKHsaqDEmYB3PK+CNr3fy5je7KCgqZkSf1jz2o0SaNozwdWg1whKAMSbgHTmRxytfpDLru72EBgfx86vbMe7a9jSKDPV1aNXKEoAxxrh2H83h/5Zs46P1B4iuF8rDg9pzf/92RITWzXsILAEYY0wZ3+/P5s+Lt/L1tnRaNIrglzd25Me9WhFSx+4hsPsAjDGmjCtbNeIfP+/LzLFX0bRhBI/P38DQl77hs+8PBcQ9BJYAjDEBb0D7Jnz48ACm3tuLYlXG/3MNP576LSt3Zvg6tGplCcAYY3DuIbi5aws+n3gtf/pxVw5m5TFy2krGTP+OzQeO+zq8amF9AMYYU468giJmfLubV79M5cTpQoZ1b8mvBneiTWw9X4dWadYJbIwxFyH7VAFTv9rB9OW7KFblnr5tePSGROIalPslhrWSJQBjjLkEh7LzeOmL7cxN3kd4SBAPXnMZY69JoEFE7b+HwBKAMcZUgR3pJ/m/z7eyaOMhGtcP45HrO3BfvzaEh9TeewhsGKgxxlSB9nFRvHpvbxY8MpDLmzfgDx9v5oa/fMX8NWkUFfvPBTVYAjDGmIvSvXU07z54Fe880JeY+qH8+r313PLSN3zxw2G/uYfAEoAxxlwkEeGaxDgWPnI1r4zqyenCIh54O5nhr68gefcxX4d3QZYAjDHmEgUFCbd3b8mSX13HH+68kt0Zp/jJayt48O3VbD10wtfhVcg6gY0xpoqdyi9k+vLdvLZsByfzC/lxz3h+OTiR+Bjf3ENgo4CMMaaGZebk8+qyVN5esQcU7uvXlkdv6EDj+mE1GoclAGOM8ZH9Wbn8dck25qekUS8shHHXXsYDVydQPzykRj7/koaBishQEdkqIqkiMrmCZYaLyGYR2SQiMz3KnxOR793XCI/yBBFZ5W5zjojUbEo0xpga0io6kufv7s7iidcyoH0sLyzZxnXPL+MfK3aTX1jss7gumABEJBiYAtwMdAZGiUjnMsskAk8CA1W1CzDRLb8V6AX0AK4CfiMiDd3VngNeVNUOQCbwQBXsjzHG1FqJzRow7f4k5j80gMvi6vM/CzZx4wtfsWDdfop9cA+BNzWAvkCqqu5U1XxgNjCszDJjgSmqmgmgqkfc8s7A16paqKo5wAZgqIgIcAMwz13ubeDOS9oTY4zxE73bxjBnXD+mj+lDvbBgHpu9jtte+TfLth6p0XsIvEkArYB9Hu/T3DJPHYGOIrJcRFaKyFC3fD3OCb+eiDQBrgdaA7FAlqoWnmebAIjIOBFJFpHk9PR07/bKGGNqORHh+subsug/r+GvI3pw4nQBY6avZtQbK1m7N7NGYqiq+wBCgERgEDAKeENEolX1c2AR8C0wC1gBFFVmw6o6TVWTVDUpLi6uisI1xpjaIShIuLNnK7741SCevr0z2w+f5K5Xv2X8O2tIPXKyej/bi2X241y1l4h3yzylAQtVtUBVdwHbcBICqvpHVe2hqoMBcedlANEiEnKebRpjTMAICwlizMAEvnr8eibemMg329MZ8uJXTJ6/gYPZudXymd4kgNVAojtqJwwYCSwss8yHOFf/uE09HYGdIhIsIrFueTegG/C5Oo1cXwI/cdcfDSy4tF0xxhj/FxUewsQbO/L149czekA75qekMej5ZWxIy6ryz7rgIFRVLRSRR4HFQDDwlqpuEpFngGRVXejOGyIim3GaeCapaoaIRADfOH2+HAfu82j3fwKYLSLPAmuBv1f1zhljjL+KjQrnd7d34ecDE/jnqj10admoyj/DbgQzxpg6zr4PwBhjTCmWAIwxJkBZAjDGmABlCcAYYwKUJQBjjAlQlgCMMSZAWQIwxpgAZQnAGGMClCUAY4wJUJYAjDEmQFkCMMaYAFUz30hsjAlcp0/AicNw8hCcOAQnj8Dp4xDeECKjIaIRRLg/I6Od6bD64DxE0lQjSwDGmMpThdxM94R+yOMEX87PgpzKbz8oxE0M5SSHM9PuvFJJxJ0OtlObN+y3ZIw5q6gQctKdk/fJI+4J/vC5P08ehqL8c9cPi4KoZtCgObToAR2bn33v+TO8IeSfgNwsyMuGvKzS03nZ7nuP6ey0s8sVF5x/P8KiykkO50kinvNCIwOm9mEJwJhAUJB39sRd6mRe5mr91FHQ4nPXj4yBqObQoBnEdnB+lryPau5xYo/yPqbIGOdVWapQkFsmUZwnceRlQ9aes9P5J86//aBQ7xNH2eUiGkFQcOX3yUcsARjjz85pXy/nav3EIeeEWJYEQf2mzkm8QUto2dPjpN6s9HRIeI3vWoVEIKye82rYsvLrFxU6fRC5mReofZTMy4TM3WeX0wt8rXl4Qzc5eCaG6PMnjjO1j4jK788lsARgTG2jCqeOXfikfvJI+e3rwWGlr9bbXV3mat39Wb+JX12tVpngEKjX2HlVlirk51Su9nFs59n3F+oPCQ6vODlc82to2KLyMZ+HJQBjaopn+/r5Ok1PHi6/jTuswdmTd6tepU/mUU3PNsNExgRMG3aNE3GaucKjoFF85dcvzHdrH1lu4sg8f+0jJx0yUp3p/o9U5Z4AlgCMuXTFxZC9r4IRMR7TOelAOV/BGtn47Mm7ScfyO00bNHeGRhr/FhIGIU2c2lctYAnAmMoqzIeD62DPt85r30rnis2TBDtX5VHNoGEraNnLPZGX6TSNauacFIzxAUsAxlxIfg6krT57wk9LhsJcZ16TjtD5TqdJpmGrs1fr9WIDs33d+BVLAMaUdeoY7FsFe5bDnhXO1X5xoTNqpnlX6D0G2g6ANv0hKs7X0Rpz0bxKACIyFHgJCAbeVNU/lbPMcOBpnEbO9ap6j1v+Z+BWnOcOLQEeU1UVkWVAC8C9lGKIqh65pL0x5mIcPwh73av7PSvgyCanPDgMWvWGAf8JbQdC674Q0dC3sRpThS6YAEQkGJgCDAbSgNUislBVN3sskwg8CQxU1UwRaeqWDwAGAt3cRf8NXAcsc9/fq6rJVbQvxlyYqjMsb8+3sHeFc5WfuduZFxblnOSvvAvaDHBO/jU8LtuYmuRNDaAvkKqqOwFEZDYwDNjsscxYYIqqZgJ4XMkrEAGEAQKEAoerJnRjvFBcDEc2uyd89yr/pPsnGNnYacrpO85pzmnezZ4hYwKKN3/trYB9Hu/TgKvKLNMRQESW4zQTPa2qn6nqChH5EjiIkwD+pqo/eKw3XUSKgPnAs6p6zhg5ERkHjANo06aNd3tlAldhPhxc71zZ713hvEpG6DSMh4Rr3fb7ARDXycbLm4BWVZc7IUAiMAiIB74Wka5AE+AKtwxgiYhco6rf4DT/7BeRBjgJ4KfAP8puWFWnAdMAkpKSyhlEbQLamRE6bnOO5wid2ERnhE7bAc4r2i4gjPHkTQLYD7T2eB/vlnlKA1apagGwS0S2cTYhrFTVkwAi8inQH/hGVfcDqOoJEZmJ09R0TgIwppTcTNi78uyQTM8ROs2udEfo9HdH6DT1dbTG1GreJIDVQKKIJOCc+EcC95RZ5kNgFE6TThOcJqGdwGXAWBH5X5wmoOuAv4pICBCtqkdFJBS4DVhaBftj6ppzRuhsBtQZodOylztCZ4A7QqeRr6M1xq9cMAGoaqGIPAosxmnff0tVN4nIM0Cyqi505w0Rkc1AETBJVTNEZB5wA7ARp0P4M1X9SETqA4vdk38wzsn/jerYQeNHSkbo7F1x9go/c5czL7Q+tLkKutzlXOG36u08t90Yc9GknH7XWispKUmTk23UaJ1xzgidFc5zc+DsCJ02/Z2fNkLHmIsmImtUNalsuf1HmZpz3hE6rSDhGveEP9B5xEJQkG/jNaaOswRgqk/+qbPP0Nn7Lexb7TFCpwN0HuYMxywZoWNDMo2pUZYATNXxHKGzdwUcWOuM0EGg+ZXQe/TZJh0boWOMz1kCMBfvzAgdt9O2ZIROUKj7DJ0JHs/QsRE6xtQ2lgCMd0qN0Cl5ho7HCJ3WfaHLnc7VvY3QMcYvWAIw5SsZoVPywLRSI3RinLb7Pg94jNAJ9W28xphKswRgzrXiVfjqOed7SAEatHS+WLzkkQpNOtkIHWPqAEsAprRNH8DiJ+Gy66HbCOemq+i2NkLHmDrIEoA5a38KfPAQtO4H98yBkHBfR2SMqUZWjzeO4wdg9j1QPw5G/NNO/sYEAKsBGOeGrVmj4PQJeOBz+55bYwKEJYBAV1wMH453HtEwajY06+LriIwxNcQSQKBb9r+weQEMeRY6DfV1NMaYGmR9AIFsw3vw9Z+h533Q/1FfR2OMqWGWAAJVWjIseMR5VMOtL9owT2MCkCWAQJSd5nT6NmgOw9+BkDBfR2SM8QHrAwg0p0/CzJFQmAejP4L6sb6OyBjjI5YAAklxMXzwCziyCe6ZC00v93VExhgfsgQQSP71B9jyMQz9EyQO9nU0xhgfsz6AQLF+Nvz7Bej9M7hqvK+jMcbUApYAAsHeVbBwAiRcC7c8byN+jDGAlwlARIaKyFYRSRWRyRUsM1xENovIJhGZ6VH+Z7fsBxF5WcQ5+4hIbxHZ6G7zTLmpYll7nWf8NIqHu9+25/YbY864YAIQkWBgCnAz0BkYJSKdyyyTCDwJDFTVLsBEt3wAMBDoBlwJ9AGuc1ebCowFEt2X3YZa1U6fcEb8FBU4nb71Gvs6ImNMLeJNDaAvkKqqO1U1H5gNDCuzzFhgiqpmAqjqEbdcgQggDAgHQoHDItICaKiqK1VVgX8Ad17qzhgPxUUw/0FI3wLDZ0CTRF9HZIypZbxJAK2AfR7v09wyTx2BjiKyXERWishQAFVdAXwJHHRfi1X1B3f9tAts01yKpb+DbZ/Bzc9B+xt8HY0xphaqqmGgITjNOIOAeOBrEekKNAGucMsAlojINUCutxsWkXHAOIA2bdpUUbh1XMo78O0r0Gcs9B3r62iMMbWUNzWA/UBrj/fxbpmnNGChqhao6i5gG05CuAtYqaonVfUk8CnQ310//gLbBEBVp6lqkqomxcXZc+ovaPdy+PiXcNkgZ7y/McZUwJsEsBpIFJEEEQkDRgILyyzzIc7VPyLSBKdJaCewF7hOREJEJBSnA/gHVT0IHBeRfu7on/uBBVWwP4Ht2C6Ycx/EtIO7Z0Cw3ednjKnYBROAqhYCjwKLgR+Auaq6SUSeEZE73MUWAxkishmnzX+SqmYA84AdwEZgPbBeVT9y13kYeBNIdZf5tOp2KwDlZcOskaDFzvf5Rsb4OiJjTC0nziAc/5CUlKTJycm+DqP2KSqEWSNg5zL46QfODV/GGOMSkTWqmlS23NoI6oIlT0HqUrj9JTv5G2O8Zo+C8HfJ02Hlq9DvYeg9xtfRGGP8iCUAf7bra1j0G+gwGAb/wdfRGGP8jCUAf5WxA+b8FGI7wE/+biN+jDGVZgnAH+VmwcwRIEEwajZENPJ1RMYYP2SXjf6mqBDeGwOZu+H+BdA4wdcRGWP8lCUAf7P4Sdj5JdzxN2g30NfRGGP8mDUB+ZPv3oDvpsGACdDrp76Oxhjj5ywB+Isd/4JPn4COQ+HG3/s6GmNMHWAJwB+kb4O5YyCuE/zHmxAU7OuIjDF1gCWA2u7UMecxD8Ghzoif8Aa+jsgYU0dYJ3BtVlQAc++H7DQY/RHEtPV1RMaYOsQSQG2l6tzlu/sbuOt1aNPP1xEZY+oYawKqrVa9DmtmwNW/gu4jfR2NMaYOsgRQG21f6oz3v/w2uOEpX0djjKmjLAHUNke2wLyfQbMuTtNPkB0iY0z1sLNLbZKT4Yz4CYlwR/xE+ToiY0wdZp3AtUVhPsz9KRw/CD9bBI3ifR2RMaaOswRQG6jCJ7+EPcvhP/4O8ed8c5sxxlQ5awKqDVZMgbX/hGsfh64/8XU0xpgAYQnA17Z+Bp//N3QeBoOe9HU0xpgAYgnAlw5vgvkPQIvucOdrNuLHGFOjvDrjiMhQEdkqIqkiMrmCZYaLyGYR2SQiM92y60VknccrT0TudOfNEJFdHvN6VNVO+YWT6TBzJIRFwahZEFbP1xEZYwLMBTuBRSQYmAIMBtKA1SKyUFU3eyyTCDwJDFTVTBFpCqCqXwI93GUaA6nA5x6bn6Sq86poX/xH4WmYcy/kpDsjfhq29HVExpgA5E0NoC+Qqqo7VTUfmA0MK7PMWGCKqmYCqOqRcrbzE+BTVT11KQH7PVX46DHYtwrumgqtevk6ImNMgPImAbQC9nm8T3PLPHUEOorIchFZKSJDy9nOSGBWmbI/isgGEXlRRMLL+3ARGSciySKSnJ6e7kW4tdzyv8L6WXD9f0GXu3wdjTEmgFVVr2MIkAgMAkYBb4hIdMlMEWkBdAUWe6zzJHA50AdoDDxR3oZVdZqqJqlqUlxcXBWF6yM/fAxLfw9X/gdcO8nX0RhjApw3CWA/0Nrjfbxb5ikNWKiqBaq6C9iGkxBKDAc+UNWCkgJVPaiO08B0nKamuuvgBnh/nNPkM2wKiPg6ImNMgPMmAawGEkUkQUTCcJpyFpZZ5kOcq39EpAlOk9BOj/mjKNP849YKEBEB7gS+r3T0/uLEYZg1CiKjYeRMCI30dUTGGHPhUUCqWigij+I03wQDb6nqJhF5BkhW1YXuvCEishkowhndkwEgIu1wahBfldn0uyISBwiwDhhfNbtUyxTkwex7IPcY/PwzaNDc1xEZYwwAoqq+jsFrSUlJmpyc7OswvKcK74+Fje/BiH/CFbf7OiJjTAASkTWqes5DxuzW0+r0zV+ck/+P/sdO/saYWscSQHXZvAD+9Sx0G+F8raMxxtQylgCqw4F18P4vIL4v3P6yjfgxxtRKlgCq2vGDMGsk1G8CI9+F0AhfR2SMMeWyL4SpSvmnYPYoOH0Cfr4Yopr6OiJjjKmQJYCqUlwMHz7kNP+MmgXNr/R1RMYYc16WAKrKV8/B5g9h8B+g082+jsYYYy7I+gCqwsZ58NWfoMd9MGCCr6MxxhivWAK4VGlrYMEj0GYA3PaCjfgxxvgNawK6FNn7nU7fqGYw4h0IKfeJ1sYYoKCggLS0NPLy8nwdSp0VERFBfHw8oaGhXi1vCeBi5ec4wz3zT8H9C5xhn8aYCqWlpdGgQQPatWuHWE25yqkqGRkZpKWlkZCQ4NU61gR0MYqL4YNfwOHv4e7p0PQKX0dkTK2Xl5dHbGysnfyriYgQGxtbqRqW1QAuxpd/hB8+gpv+FxIH+zoaY/yGnfyrV2V/v1YDqKwNc52HvPUaDf0e8nU0xhhz0SwBVMa+72DBo9DuGrjlLzbixxg/kpWVxauvvnpR695yyy1kZWVVbUC1gCUAb2Xtdb7YpWFLGP4PCAnzdUTGmEo4XwIoLCw877qLFi0iOjq6GqLyTlFRUbVs1/oAvHH6hPOVjoX5MGYu1Gvs64iM8Wu//2gTmw8cr9Jtdm7ZkN/d3qXC+ZMnT2bHjh306NGDwYMHc+utt/LUU08RExPDli1b2LZtG3feeSf79u0jLy+Pxx57jHHjxgHQrl07kpOTOXnyJDfffDNXX3013377La1atWLBggVERpb+mtf33nuP3//+9wQHB9OoUSO+/vprioqKeOKJJ/jss88ICgpi7NixTJgwgS+++ILf/OY3FBYW0qdPH6ZOnUp4eDjt2rVjxIgRLFmyhMcff5zGjRvzu9/9jtOnT9O+fXumT59OVFTUJf3OrAZwIcVFzpe5H/kBhs+AuI6+jsgYcxH+9Kc/0b59e9atW8fzzz8PQEpKCi+99BLbtm0D4K233mLNmjUkJyfz8ssvk5GRcc52tm/fziOPPMKmTZuIjo5m/vz55yzzzDPPsHjxYtavX8/Chc5XqE+bNo3du3ezbt06NmzYwL333kteXh5jxoxhzpw5bNy4kcLCQqZOnXpmO7GxsaSkpHDjjTfy7LPPsnTpUlJSUkhKSuKFF1645N+J1QAu5Ivfw9ZFTpt/+xt8HY0xdcL5rtRrUt++fUuNmX/55Zf54IMPANi3bx/bt28nNja21DoJCQn06NEDgN69e7N79+5ztjtw4EDGjBnD8OHD+fGPfwzA0qVLGT9+PCEhzmm3cePGrF+/noSEBDp2dC4sR48ezZQpU5g4cSIAI0aMAGDlypVs3ryZgQMHApCfn0///v0vef8tAZzP2ndh+UvQ50HoO9bX0Rhjqlj9+vXPTC9btoylS5eyYsUK6tWrx6BBg8odUx8efvaO/+DgYHJzc89Z5rXXXmPVqlV88skn9O7dmzVr1lxSfKrK4MGDmTVr1kVtpyLWBFSRPSvgo8fgskEw9E++jsYYc4kaNGjAiRMnKpyfnZ1NTEwM9erVY8uWLaxcufKiP2vHjh1cddVVPPPMM8TFxbFv3z4GDx7M66+/fqbD+dixY3Tq1Indu3eTmpoKwDvvvMN11113zvb69evH8uXLzyyXk5NzptnqUlgCKE/mbphzL8S0hbtnQLB3z9UwxtResbGxDBw4kCuvvJJJkyadM3/o0KEUFhZyxRVXMHnyZPr163fRnzVp0iS6du3KlVdeyYABA+jevTsPPvggbdq0oVu3bnTv3p2ZM2cSERHB9OnTufvuu+natStBQUGMHz/+nO3FxcUxY8YMRo0aRbdu3ejfvz9btmy56PhKiKpeeCGRocBLQDDwpqqec0ksIsOBpwEF1qvqPSJyPfCix2KXAyNV9UMRSQBmA7HAGuCnqpp/vjiSkpI0OTnZqx27aHnH4e9D4MRBGPsviG1fvZ9nTID44YcfuOIKe2xKdSvv9ywia1Q1qeyyF6wBiEgwMAW4GegMjBKRzmWWSQSeBAaqahdgIoCqfqmqPVS1B3ADcAr43F3tOeBFVe0AZAIPVGIfq0dxEcx/ADK2O2P97eRvjKnDvGkC6gukqupO9wp9NjCszDJjgSmqmgmgqkfK2c5PgE9V9ZQ4D6y4AZjnznsbuPMi4q9aS/4Htn8OtzwPl53bDmeMMXWJNwmgFbDP432aW+apI9BRRJaLyEq3yaiskUBJF3YskKWqJbfflbdNAERknIgki0hyenq6F+FepDVvw4q/wVXjIenn1fc5xhhTS1RVJ3AIkAgMAkYBb4hIdMlMEWkBdAUWV3bDqjpNVZNUNSkuLq5qoi1r1zfwya+g/Y9gyB+r5zOMMaaW8SYB7Adae7yPd8s8pQELVbVAVXcB23ASQonhwAeqWuC+zwCiRaTkPoTytlkzju2EuT+Fxu2dZ/sH260RxpjA4E0CWA0kikiCiIThNOUsLLPMhzhX/4hIE5wmoZ0e80dxtvkHdYYefYnTLwAwGlhQ+fAvUV42zBwBCNwzGyIa1XgIxhjjKxdMAG47/aM4zTc/AHNVdZOIPCMid7iLLQYyRGQzzol9kqpmAIhIO5waxFdlNv0E8CsRScXpE/h7FeyP94oK4b2fwbFdMOKf0PiyGv14Y0ztd6kPW6vtvGrvUNVFwKIyZf/jMa3Ar9xX2XV3U04Hr6ruxBlh5BuLfws7voA7XoF2A30WhjEmsBUWFp55PlBNC8wG79VvwnevQ/9Hodf9vo7GmMDz6WQ4tLFqt9m8K9xc8WNbJk+eTOvWrXnkkUcAePrpp4mKimL8+PEMGzaMzMxMCgoKePbZZxk2rOxI97NycnIYPnw4aWlpFBUV8dRTTzFixAhWr17NY489Rk5ODuHh4XzxxReEhoby0EMPkZycTEhICC+88ALXX389M2bM4P333+fkyZMUFRWxaNEiJkyYwPfff09BQQFPP/30eWOoKoGXAHZ8CYseh8SbYPAzvo7GGFNDRowYwcSJE88kgLlz57J48WIiIiL44IMPaNiwIUePHqVfv37ccccdFX6/7meffUbLli355JNPAOcZQvn5+YwYMYI5c+bQp08fjh8/TmRkJC+99BIiwsaNG9myZQtDhgw58wyflJQUNmzYQOPGjfntb3/LDTfcwFtvvUVWVhZ9+/blxhtvLPWwuuoQWAngaCq8NxriOsF/vAlBwb6OyJjAdJ4r9erSs2dPjhw5woEDB0hPTycmJobWrVtTUFDAb3/7W77++muCgoLYv38/hw8fpnnz5uVup2vXrvz617/miSee4LbbbuOaa65h48aNtGjRgj59+gDQsGFDAP79738zYcIEAC6//HLatm17JgEMHjyYxo2dL5f6/PPPWbhwIX/5y18AyMvLY+/evdX+6IzASQC5mTBzOASFwqjZENHQ1xEZY2rY3Xffzbx58zh06NCZZ+2/++67pKens2bNGkJDQ2nXrl25j4Eu0bFjR1JSUli0aBH//d//zY9+9CPuuuuuSsfieXWvqsyfP59OnTpVfqcuQWA8DbSoAOaOhux9zoifmLa+jsgY4wMjRoxg9uzZzJs3j7vvvhtwmnCaNm1KaGgoX375JXv27DnvNg4cOEC9evW47777mDRpEikpKXTq1ImDBw+yevVqAE6cOEFhYSHXXHMN7777LgDbtm1j79695Z7kb7rpJl555RVKHs65du3aqtztCtX9GoAqfPo47PoK7pwKbS/9W3SMMf6pS5cunDhxglatWtGiRQsA7r33Xm6//Xa6du1KUlISl19++Xm3sXHjRiZNmkRQUBChoaFMnTqVsLAw5syZw4QJE8jNzSUyMpKlS5fy8MMP89BDD9G1a1dCQkKYMWNGqS+UKfHUU08xceJEunXrRnFxMQkJCXz88cfV8jvw5NXjoGuLi3octCqsnAo56XDj76onMGPMBdnjoGtGZR4HXfdrACLQ/2FfR2GMMbVOYPQBGGOMOYclAGNMjfGnJmd/VNnfryUAY0yNiIiIICMjw5JANVFVMjIyiIiI8Hqdut8HYIypFeLj40lLS6Nav9gpwEVERBAfH+/18pYAjDE1IjQ0lISEBF+HYTxYE5AxxgQoSwDGGBOgLAEYY0yA8qs7gUUkHTj/gzpqXhPgqK+DqCa2b/6rLu+f7VvltVXVuLKFfpUAaiMRSS7vFuu6wPbNf9Xl/bN9qzrWBGSMMQHKEoAxxgQoSwCXbpqvA6hGtm/+qy7vn+1bFbE+AGOMCVBWAzDGmABlCcAYYwKUJQBARFqLyJcisllENonIY255YxFZIiLb3Z8xbrmIyMsikioiG0Skl8e2RrvLbxeR0R7lvUVko7vOyyIiNbyPwSKyVkQ+dt8niMgqN545IhLmloe771Pd+e08tvGkW75VRG7yKB/qlqWKyOQa3q9oEZknIltE5AcR6V/Hjtsv3b/J70VklohE+OuxE5G3ROSIiHzvUVbtx6qiz6iBfXve/bvcICIfiEi0x7xKHY+LOeZeUdWAfwEtgF7udANgG9AZ+DMw2S2fDDznTt8CfAoI0A9Y5ZY3Bna6P2Pc6Rh33nfusuKue3MN7+OvgJnAx+77ucBId/o14CF3+mHgNXd6JDDHne4MrAfCgQRgBxDsvnYAlwFh7jKda3C/3gYedKfDgOi6ctyAVsAuINLjmI3x12MHXAv0Ar73KKv2Y1XRZ9TAvg0BQtzp5zz2rdLHo7LH3Ou4a+qP2Z9ewAJgMLAVaOGWtQC2utOvA6M8lt/qzh8FvO5R/rpb1gLY4lFearka2J944AvgBuBj9x/kqMcfZ39gsTu9GOjvToe4ywnwJPCkxzYXu+udWdctL7VcNe9XI5wTpJQpryvHrRWwD+dkF+Ieu5v8+dgB7Sh9kqz2Y1XRZ1T3vpWZdxfwbnm/5wsdj4v5f/U2ZmsCKsOtQvUEVgHNVPWgO+sQ0MydLvnHLJHmlp2vPK2c8pryV+BxoNh9HwtkqWphOfGc2Qd3fra7fGX3uSYkAOnAdHGat94UkfrUkeOmqvuBvwB7gYM4x2INdePYlaiJY1XRZ9Skn+PUSqDy+3Yx/69esQTgQUSigPnARFU97jlPnRTrd2NmReQ24IiqrvF1LNUgBKfaPVVVewI5OFX8M/z1uAG4bdXDcBJdS6A+MNSnQVWjmjhWvvh7EJH/AgqBd2vyc71hCcAlIqE4J/93VfV9t/iwiLRw57cAjrjl+4HWHqvHu2XnK48vp7wmDATuEJHdwGycZqCXgGgRKflCIM94zuyDO78RkEHl97kmpAFpqrrKfT8PJyHUheMGcCOwS1XTVbUAeB/neNaFY1eiJo5VRZ9R7URkDHAbcK+bfKDy+5ZB5Y+5d6qzvc9fXjhtbP8A/lqm/HlKdx792Z2+ldIdVN+55Y1x2qRj3NcuoLE7r2wH1S0+2M9BnO0Efo/SnUoPu9OPULpTaa473YXSHVc7cTqtQtzpBM52XHWpwX36BujkTj/tHrM6cdyAq4BNQD33898GJvjzsePcPoBqP1YVfUYN7NtQYDMQV2a5Sh+Pyh5zr2OuqT/m2vwCrsapFm4A1rmvW3Da0r4AtgNLPf7QBJiC02O/EUjy2NbPgVT39TOP8iTge3edv1GJjpoq3M9BnE0Al7n/MKnuH1e4Wx7hvk9151/msf5/ufFvxWM0jPu72ubO+68a3qceQLJ77D50Twp15rgBvwe2uDG84540/PLYAbNw+jIKcGpvD9TEsaroM2pg31Jx2ufXua/XLvZ4XMwx9+Zlj4IwxpgAZX0AxhgToCwBGGNMgLIEYIwxAcoSgDHGBChLAMYYE6AsARhjTICyBGCMMQHq/wOtCSRMz6D72wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building and evaluating a baseline logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = Pipeline(steps=[\n",
    "    (\"preprocessing\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop = [\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42))    \n",
    "])\n",
    "\n",
    "evaluate_model(lr_clf, X_train, y_train, X_test, y_test, curves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9552    0.9536    0.9544     72669\n",
      "High income (>50k)     0.4626    0.4718    0.4672      6157\n",
      "\n",
      "          accuracy                         0.9159     78826\n",
      "         macro avg     0.7089    0.7127    0.7108     78826\n",
      "      weighted avg     0.9167    0.9159    0.9163     78826\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building and evaluating a baseline decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(dt_clf, X_train, y_train, X_test, y_test, curves=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple things worth noting :\n",
    "- The **decision tree performs a little bit better** than the logistic regression model. The difference is however not that big. We will therefore continue to compare the both of them throughout the next steps.\n",
    "- Depending on the context, we could favor one based on individual f1, recall or sensitivity scores for one of the two classes.\n",
    "- Overall, the performance is not very good. While the f1 score is not too bad on the majority class (low income) it is, as could be expected, quite poor for the minority class (high income).\n",
    "\n",
    "To adress the issue of underfitting, we will try the following pre-processing operations :\n",
    "- Perform over-sampling to increase the representation of the minority class\n",
    "- Perform some feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.3 : Over sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try and perform over sampling through a SMOTE algorithm (Synthetic Minority Oversampling TEchnique). The goal is to artificially create observations for the minority class \"in between\" real observations from the same class in the feature space, up until the two classes have an equal number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9855    0.8517    0.9137     72669\n",
      "High income (>50k)     0.3273    0.8520    0.4730      6157\n",
      "\n",
      "          accuracy                         0.8517     78826\n",
      "         macro avg     0.6564    0.8518    0.6933     78826\n",
      "      weighted avg     0.9341    0.8517    0.8793     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try and perform over sampling on the log reg model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "\n",
    "lr_clf_with_smote = imPipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"resampling\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"classifier\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(lr_clf_with_smote, X_train, y_train, X_test, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9576    0.9407    0.9491     72669\n",
      "High income (>50k)     0.4206    0.5082    0.4603      6157\n",
      "\n",
      "          accuracy                         0.9069     78826\n",
      "         macro avg     0.6891    0.7244    0.7047     78826\n",
      "      weighted avg     0.9156    0.9069    0.9109     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same with decision tree\n",
    "dt_clf_with_smote = imPipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"resampling\", SMOTE(sampling_strategy=\"auto\", random_state=42)),\n",
    "    (\"classifier\", DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "evaluate_model(dt_clf_with_smote, X_train, y_train, X_test, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe two different results :\n",
    "- Oversampling did improve the average f1 score of our logistic regression model, although not very much (~ +0.5%)\n",
    "- The same operation dit **not** improve the performance of our decision tree (~ -1%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.4 : Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried adding observations. Let us now try to add features.\n",
    "\n",
    "Since we want to preserve some degree of \"explainability\" in our model, we will not make us of feature engineering algorithm such as polynomial features.\n",
    "\n",
    "However, we can try and add a couple of features **manually**, following from what we saw during our EDA (see part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_binary_features(X):\n",
    "\n",
    "    X_ = X.copy()\n",
    "\n",
    "    X_[\"adult\"] = X_[\"age\"].map(lambda val: 1 if val >= 18 else 0)\n",
    "\n",
    "    X_[\"working\"] = X_[\"weeks worked in year\"].map(lambda val: 1 if val > 0 else 0)\n",
    "\n",
    "    X_[\"extra earnings\"] = X_.apply(lambda row: 1 if row[[\"capital gains\", \"dividends from stocks\"]].sum() > 0 else 0, axis=1)\n",
    "\n",
    "    X_[\"is hispanic\"] = X_[\"hispanic origin\"].map(lambda val: 0 if val == \"All other\" else 1)\n",
    "\n",
    "    X_[\"high academic level\"] = X_[\"education\"].map(\n",
    "        lambda val: 1 if val in [\"Bachelors degree(BA AB BS)\", \"Masters degree(MA MS MEng MEd MSW MBA)\", \"Prof school degree (MD DDS DVM LLB JD)\", \"Doctorate degree(PhD EdD)\"] else 0\n",
    "    )\n",
    "    \n",
    "    # According to occupation recodes from documentation page 146\n",
    "    X_[\"executive or manager\"] = X_[\"detailed occupation recode\"].map(lambda val: 1 if val <=3 else 0) \n",
    "\n",
    "    # According to industry recodes from documentation page 131\n",
    "    X_[\"work in agriculture or industry\"] = X_[\"detailed industry recode\"].map(lambda val: 1 if val<=20 else 0)\n",
    "    X_[\"work in finance, insurance, real estate or business management\"] = X_[\"detailed industry recode\"].map(lambda val: 1 if val in [32, 33, 34, 37] else 0)\n",
    "\n",
    "    return X_\n",
    "\n",
    "X_train_extra_features = add_binary_features(X_train)\n",
    "X_test_extra_features = add_binary_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9873    0.8469    0.9117     72669\n",
      "High income (>50k)     0.3252    0.8710    0.4736      6157\n",
      "\n",
      "          accuracy                         0.8487     78826\n",
      "         macro avg     0.6562    0.8589    0.6926     78826\n",
      "      weighted avg     0.9355    0.8487    0.8775     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try our new features with the log reg model\n",
    "lr_clf_with_extra_features = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(lr_clf_with_extra_features, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9562    0.9559    0.9560     72669\n",
      "High income (>50k)     0.4813    0.4835    0.4824      6157\n",
      "\n",
      "          accuracy                         0.9190     78826\n",
      "         macro avg     0.7188    0.7197    0.7192     78826\n",
      "      weighted avg     0.9191    0.9190    0.9190     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same with decision tree\n",
    "dt_clf_with_extra_features = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", DecisionTreeClassifier(criterion=\"entropy\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(dt_clf_with_extra_features, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we do have a slight improvement for both models compared to the baseline ones (~ + 0.4% for log reg and +0.6% for decision tree)\n",
    "\n",
    "We can now try to find which of the features had the most \"impact\" on prediction in the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>executive or manager</td>\n",
       "      <td>0.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>region of previous residence</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fill inc questionnaire for veteran's admin</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>age</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>detailed household and family stat</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>state of previous residence</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weeks worked in year</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>family members under 18</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>detailed occupation recode</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>capital losses</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>working</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>country of birth father</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>work in agriculture or industry</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>class of worker</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>education</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hispanic origin</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>major occupation code</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>detailed household summary in household</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>country of birth mother</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reason for unemployment</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>citizenship</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high academic level</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>capital gains</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num persons worked for employer</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>year</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dividends from stocks</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>major industry code</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>marital stat</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wage per hour</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>veterans benefits</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>enroll in edu inst last wk</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>race</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>tax filer stat</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>is hispanic</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detailed industry recode</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>country of birth self</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>adult</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>live in this house 1 year ago</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>work in finance, insurance, real estate or bus...</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>member of a labor union</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>own business or self employed</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extra earnings</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>full or part time employment stat</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  coef\n",
       "40                               executive or manager 0.172\n",
       "29                       region of previous residence 0.129\n",
       "33         fill inc questionnaire for veteran's admin 0.127\n",
       "15                                                age 0.058\n",
       "38                 detailed household and family stat 0.050\n",
       "14                        state of previous residence 0.049\n",
       "30                               weeks worked in year 0.041\n",
       "1                             family members under 18 0.038\n",
       "24                         detailed occupation recode 0.032\n",
       "12                                     capital losses 0.028\n",
       "32                                            working 0.028\n",
       "34                            country of birth father 0.026\n",
       "19                    work in agriculture or industry 0.019\n",
       "28                                    class of worker 0.016\n",
       "35                                          education 0.016\n",
       "6                                     hispanic origin 0.015\n",
       "8                               major occupation code 0.013\n",
       "25            detailed household summary in household 0.012\n",
       "27                            country of birth mother 0.012\n",
       "3                             reason for unemployment 0.011\n",
       "31                                        citizenship 0.010\n",
       "7                                 high academic level 0.010\n",
       "11                                      capital gains 0.009\n",
       "18                    num persons worked for employer 0.009\n",
       "23                                                sex 0.009\n",
       "26                                               year 0.009\n",
       "16                              dividends from stocks 0.007\n",
       "21                                major industry code 0.007\n",
       "10                                       marital stat 0.005\n",
       "17                                      wage per hour 0.005\n",
       "13                                  veterans benefits 0.005\n",
       "5                          enroll in edu inst last wk 0.004\n",
       "20                                               race 0.004\n",
       "43                                     tax filer stat 0.004\n",
       "39                                        is hispanic 0.003\n",
       "2                            detailed industry recode 0.002\n",
       "22                              country of birth self 0.002\n",
       "42                                              adult 0.001\n",
       "9                       live in this house 1 year ago 0.001\n",
       "41  work in finance, insurance, real estate or bus... 0.001\n",
       "37                            member of a labor union 0.000\n",
       "4                       own business or self employed 0.000\n",
       "0                                      extra earnings 0.000\n",
       "36                  full or part time employment stat 0.000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance in the decision tree\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "dt_feature_imp = pd.DataFrame(data={\n",
    "    \"features\": list(set(X_train_extra_features.columns).difference(set([\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]))),\n",
    "    \"coef\": list(dt_clf_with_extra_features[\"classifier\"].feature_importances_)\n",
    "})\n",
    "\n",
    "dt_feature_imp.sort_values(\"coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, one of our custom features (executive or manager) is ranking first. On the other hand, the other added features did not provide as much.\n",
    "\n",
    "Note that if we have to deal with overfitting with a tree-based model, we could try to perform feature selection based on this ranking (eliminating, for instance, the N lowest ranking features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.5 : More complex models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we found a couple of preprocessing tricks to improve model performance, there is still room for improvement. Before diving into fine-tuning, we can try out a couple of different models, a little bit more elaborate than our two baselines models.\n",
    "\n",
    "Following the results above, we will use our newly created features. The will get rid of SMOTE resampling for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9514    0.9872    0.9690     72669\n",
      "High income (>50k)     0.7283    0.4052    0.5207      6157\n",
      "\n",
      "          accuracy                         0.9417     78826\n",
      "         macro avg     0.8398    0.6962    0.7448     78826\n",
      "      weighted avg     0.9340    0.9417    0.9340     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(rf_clf, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9528    0.9876    0.9699     72669\n",
      "High income (>50k)     0.7426    0.4221    0.5383      6157\n",
      "\n",
      "          accuracy                         0.9434     78826\n",
      "         macro avg     0.8477    0.7049    0.7541     78826\n",
      "      weighted avg     0.9363    0.9434    0.9362     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosted trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbt_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(gbt_clf, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Low income (<50k)     0.9824    0.8895    0.9336     72669\n",
      "High income (>50k)     0.3836    0.8116    0.5209      6157\n",
      "\n",
      "          accuracy                         0.8834     78826\n",
      "         macro avg     0.6830    0.8505    0.7273     78826\n",
      "      weighted avg     0.9356    0.8834    0.9014     78826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=False, #One hot encoding\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", SGDClassifier(loss=\"log\", class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "evaluate_model(sgd_clf, X_train_extra_features, y_train, X_test_extra_features, y_test, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any fine-tuning, we can already see that all of these models already outperform our two baselines models.\n",
    "\n",
    "In the next section, we will compare them with different sets of hyperparameters to find the best predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **#2.6 : Feature selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into fine tuning, it is worth noting that feature selection can sometimes improve model performance, getting rid of noise and avoiding dimensionality issues. As a final preprocessing step, we will perform Univariate Feature Selection on each on the 3 models (RF, GB, SGD) to find the optimal number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for k in [2, 4, 8, 16, 32, 40, X_train_extra_features.shape[1]]\n",
    "    rf_clf = Pipeline(steps=[\n",
    "        (\"preprocessor\", build_preprocessor(\n",
    "            ordinal_encoding=True,\n",
    "            cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "        )),\n",
    "        (\"feature_selec\", SelectKBest(k)),\n",
    "        (\"classifier\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "    ])\n",
    "    y_pred = rf_clf.fit(X_train_extra_features, y_train).predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    print(\"Score with {k} features : {score}\")\n",
    "\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", build_preprocessor(\n",
    "        ordinal_encoding=True,\n",
    "        cols_to_drop=[\"migration code-change in msa\", \"migration code-change in reg\", \"migration code-move within reg\", \"migration prev res in sunbelt\"]\n",
    "    )),\n",
    "    (\"classifier\", RandomForestClassifier(class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "    max_nb_of_features = \n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b0d1bc37e4150564005d2f0757eca3230f3c8295ef7a49a1da484b71996b598"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
